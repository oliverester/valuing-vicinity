arch: unet
encoder: resnet18
gpu: 5
workers: 8
batch-size: 32
val-batch-size: 256
epochs: 200
train-data: /homes/oester/repositories/prae/data/segmentation/preprocessed/train/CAMELYON_d8_train
reload-model-folder: /homes/oester/repositories/prae/logdir_sem_seg/camelyon_d8_unet_resnet18/attention_segmentation-2022-02-18_09_19_30
label-map-file: /homes/oester/repositories/prae/data/segmentation/label_map_camelyon.json
patch-label-type: mask
draw-patches-per-class: 100
vali-split: 0.2
learning-rate: 0.0001
lr-gamma: 0.95
adjust-lr: true
image-label-in-path: false
include-classes: [0,1,2]
normalize: true
logdir: logdir_sem_seg/camelyon_d8_unet_resnet18
evaluate-every: 10
warm-up-epochs: 5
early-stopping-epochs: 10
criterion: 'cross_entropy'
use-ce-weights: false
n-eval-wsis: 4
overlay-polygons: true
embedding-dim: 1024
k-neighbours: 16
use-ln: true
use-pos-encoding: true
learn-pos-encoding: false
num-attention-heads: 8
attention-hidden-dim: 1024
use-self-attention: false
log-details: false
memory-to-gpu: true
seed: 13
performance-metric: loss
attention-on : false
multiscale-on: false